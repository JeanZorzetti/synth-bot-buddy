# üéØ SPRINTS REFORMULADOS - Baseado nas Descobertas da Fase 0

## üéØ SPRINT 1: Valida√ß√£o do Modelo Multi-Class em Produ√ß√£o (Semana 1) üÜï

**Objetivo**: Validar se o modelo multi-class corrige os problemas cr√≠ticos identificados na Fase 0 e estabelecer baseline de performance real.

**Status**: üîµ PR√ìXIMO - Aguardando estabiliza√ß√£o do deploy

**Pr√©-requisitos**:
- ‚úÖ Modelo multi-class treinado (xgboost_multiclass_20251218_114940.pkl)
- ‚úÖ Timeout ajustado para 180 minutos
- ‚úÖ ml_predictor.py com suporte multi-class
- ‚úÖ Deploy em produ√ß√£o (botderivapi.roilabs.com.br)
- ‚è≥ Bug UnboundLocalError corrigido

---

### 1.1 Teste de Valida√ß√£o Inicial (50 trades)
**Objetivo**: Confirmar que modelo prev√™ as 3 classes e timeout est√° funcionando

**A√ß√£o**:
- [ ] Iniciar forward testing em produ√ß√£o com modelo multi-class
- [ ] Executar 50 trades (m√≠nimo para valida√ß√£o estat√≠stica)
- [ ] Monitorar logs em tempo real para erros cr√≠ticos
- [ ] Coletar m√©tricas a cada 10 trades

**M√©tricas para Monitorar**:
```
- Distribui√ß√£o de predi√ß√µes (target: 20-40% cada classe)
- Timeout rate (target: <30%, baseline: 92%)
- Win rate (target: >40%, baseline: 15.38%)
- Confidence m√©dia (target: >45%)
- SL hit rate (baseline: 8%)
- TP hit rate (baseline: 0%)
```

**Crit√©rios de Sucesso**:
- ‚úÖ Modelo prev√™ TODAS as 3 classes (n√£o >70% em uma √∫nica)
- ‚úÖ Timeout rate < 30% (prova que 180min funciona)
- ‚úÖ Win rate > 35% (melhoria de 2x sobre baseline)
- ‚úÖ Sem erros cr√≠ticos no ml_predictor.py

**Se FALHAR**: Voltar para an√°lise adicional e investigar causa raiz

---

### 1.2 An√°lise Detalhada de Performance
**Objetivo**: Entender quando e por que o modelo acerta/erra

**A√ß√£o**:
- [ ] Exportar hist√≥rico de trades via `/api/forward-testing/export/csv`
- [ ] Criar notebook Jupyter de an√°lise post-mortem
- [ ] Gerar relat√≥rio com insights acion√°veis

**An√°lises a Realizar**:
```python
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# 1. Win rate por tipo de predi√ß√£o
win_rate_by_class = df.groupby('prediction').agg({
    'profit_loss': lambda x: (x > 0).mean() * 100,
    'id': 'count'
}).round(2)

# 2. Correlation entre confidence e profit
plt.scatter(df['confidence'], df['profit_loss'])
plt.xlabel('Confidence')
plt.ylabel('P&L ($)')
plt.title('Confidence vs Profit Correlation')

# 3. Win rate por hora do dia
df['hour'] = pd.to_datetime(df['timestamp']).dt.hour
hourly_wr = df.groupby('hour')['profit_loss'].apply(lambda x: (x > 0).mean() * 100)

# 4. Identificar piores trades
worst_trades = df.nsmallest(10, 'profit_loss')
print("Top 10 piores trades:")
print(worst_trades[['prediction', 'confidence', 'profit_loss', 'exit_reason', 'duration_minutes']])

# 5. An√°lise de drawdown sequences
df['is_loss'] = df['profit_loss'] < 0
df['loss_streak'] = (df['is_loss'] != df['is_loss'].shift()).cumsum()
max_streak = df[df['is_loss']].groupby('loss_streak').size().max()
print(f"Maior sequ√™ncia de perdas: {max_streak} trades")
```

**Entreg√°vel**:
- PDF: `fase1_analise_performance.pdf` com gr√°ficos e insights
- Lista de hip√≥teses para Sprint 2
- Identifica√ß√£o de padr√µes espec√≠ficos de falha

---

### 1.3 Calibra√ß√£o de Confidence Threshold
**Objetivo**: Encontrar threshold √≥timo que maximize Sharpe Ratio

**Contexto**: Threshold 0.40 foi escolhido empiricamente, pode n√£o ser √≥timo para modelo multi-class

**A√ß√£o**:
- [ ] Simular performance com diferentes thresholds usando trades hist√≥ricos
- [ ] Testar: 0.35, 0.38, 0.40, 0.42, 0.45, 0.50
- [ ] Para cada threshold, calcular:
  - Total de trades executados
  - Win rate
  - Profit Factor
  - Sharpe Ratio
  - Max Drawdown
  - Expectancy ($)

**C√≥digo de Simula√ß√£o**:
```python
thresholds = [0.35, 0.38, 0.40, 0.42, 0.45, 0.50]
results = []

for thresh in thresholds:
    # Filtrar trades com confidence >= threshold
    filtered = df[df['confidence'] >= thresh]

    if len(filtered) < 20:  # M√≠nimo 20 trades
        continue

    wins = filtered[filtered['profit_loss'] > 0]
    losses = filtered[filtered['profit_loss'] < 0]

    win_rate = len(wins) / len(filtered) * 100
    profit_factor = wins['profit_loss'].sum() / abs(losses['profit_loss'].sum()) if len(losses) > 0 else 0
    sharpe = filtered['profit_loss'].mean() / filtered['profit_loss'].std() if filtered['profit_loss'].std() > 0 else 0
    expectancy = filtered['profit_loss'].mean()

    results.append({
        'threshold': thresh,
        'trades': len(filtered),
        'win_rate': round(win_rate, 2),
        'profit_factor': round(profit_factor, 2),
        'sharpe': round(sharpe, 2),
        'expectancy': round(expectancy, 2)
    })

# Exibir tabela comparativa
results_df = pd.DataFrame(results)
print(results_df.to_string(index=False))

# Encontrar threshold com melhor Sharpe
best = max(results, key=lambda x: x['sharpe'])
print(f"\nMelhor threshold: {best['threshold']} (Sharpe: {best['sharpe']:.2f}, WR: {best['win_rate']}%)")
```

**Crit√©rio de Decis√£o**:
- Se Sharpe melhora >15%: Atualizar threshold em produ√ß√£o
- Se mudan√ßa <10%: Manter 0.40
- Considerar trade-off entre volume de trades vs qualidade

**Resultado Esperado**:
- Threshold √≥timo identificado e documentado
- Sharpe Ratio > 1.0

---

## üéØ SPRINT 2: Otimiza√ß√£o de Par√¢metros (Semana 2) üîÑ

**Objetivo**: Otimizar SL/TP/Timeout e adicionar filtros contextuais (SE necess√°rio)

**Status**: üü° CONDICIONAL - S√≥ executar se Sprint 1 atingir >40% win rate

**Pr√©-condi√ß√£o**: Sprint 1 deve ter gerado >50 trades e win rate >35%

---

### 2.1 Grid Search para SL/TP √ìtimos
**Problema**: SL=2%, TP=4% foram escolhidos empiricamente

**A√ß√£o**:
- [ ] Usar dados hist√≥ricos de forward testing como baseline
- [ ] Testar combina√ß√µes de par√¢metros:
  - SL: [1.5%, 2.0%, 2.5%, 3.0%]
  - TP: [3.0%, 4.0%, 5.0%, 6.0%]
  - Risk:Reward Ratios: [1:1.5, 1:2, 1:2.5, 1:3]
- [ ] Para cada combina√ß√£o, simular P&L, Win Rate, Sharpe
- [ ] Identificar combina√ß√£o com melhor Profit Factor

**C√≥digo de Grid Search**:
```python
from itertools import product

sl_options = [1.5, 2.0, 2.5, 3.0]
tp_options = [3.0, 4.0, 5.0, 6.0]

results = []

for sl, tp in product(sl_options, tp_options):
    # Simular trades com novos SL/TP
    simulated_df = simulate_trades(df, sl_pct=sl, tp_pct=tp)

    wins = simulated_df[simulated_df['profit_loss'] > 0]
    losses = simulated_df[simulated_df['profit_loss'] < 0]

    win_rate = len(wins) / len(simulated_df) * 100
    profit_factor = wins['profit_loss'].sum() / abs(losses['profit_loss'].sum())
    total_pnl = simulated_df['profit_loss'].sum()

    results.append({
        'sl': sl,
        'tp': tp,
        'risk_reward': tp / sl,
        'win_rate': round(win_rate, 2),
        'profit_factor': round(profit_factor, 2),
        'total_pnl': round(total_pnl, 2),
        'trades': len(simulated_df)
    })

# Ordenar por Profit Factor
results_df = pd.DataFrame(results).sort_values('profit_factor', ascending=False)
print("Top 10 combina√ß√µes:")
print(results_df.head(10).to_string(index=False))
```

**Crit√©rio de Decis√£o**:
- Escolher combina√ß√£o com melhor Profit Factor E Sharpe > 1.0
- Considerar trade-off entre win rate e expectancy

**Resultado Esperado**: SL/TP otimizados identificados

---

### 2.2 Valida√ß√£o de Timeout (180 min)
**Objetivo**: Confirmar se 180 min √© realmente √≥timo ou pode ser ajustado

**A√ß√£o**:
- [ ] Analisar dura√ß√£o m√©dia dos trades vencedores
- [ ] Calcular percentil 90 de dura√ß√£o dos winners
- [ ] Verificar se timeout est√° "cortando" trades vencedores
- [ ] Testar timeouts: [120min, 150min, 180min, 240min]

**An√°lise de Dura√ß√£o**:
```python
winners = df[df['profit_loss'] > 0]
losers = df[df['profit_loss'] < 0]

print("Dura√ß√£o m√©dia - Winners:", winners['duration_minutes'].mean())
print("Dura√ß√£o m√©dia - Losers:", losers['duration_minutes'].mean())
print("Percentil 90 - Winners:", winners['duration_minutes'].quantile(0.9))

# Analisar trades que deram timeout
timeouts = df[df['exit_reason'] == 'timeout']
timeout_pnl = timeouts['profit_loss'].mean()
print(f"P&L m√©dio de trades timeout: ${timeout_pnl:.2f}")
```

**Crit√©rio**: Se percentil 90 de winners > 180min, aumentar timeout

---

### 2.3 Filtros de Contexto (CONDICIONAL)
**Objetivo**: Adicionar filtros APENAS SE win rate ainda < 45% ap√≥s otimizar SL/TP

**Problema**: Modelo pode estar entrando em mercado lateral (sem tend√™ncia)

**A√ß√£o**:
- [ ] Calcular ADX (Average Directional Index) para todos os trades hist√≥ricos
- [ ] Verificar se win rate √© maior quando ADX > 25
- [ ] Se SIM (diferen√ßa >10%): Implementar filtro ADX
- [ ] Testar com backtesting antes de deploy

**C√≥digo de An√°lise**:
```python
# Adicionar ADX aos dados hist√≥ricos
df['adx'] = calcular_adx(df)  # Requer recalcular com dados OHLC

# Comparar win rate com/sem ADX
high_adx = df[df['adx'] > 25]
low_adx = df[df['adx'] <= 25]

wr_high = (high_adx['profit_loss'] > 0).mean() * 100
wr_low = (low_adx['profit_loss'] > 0).mean() * 100

print(f"Win rate com ADX>25: {wr_high:.2f}%")
print(f"Win rate com ADX<=25: {wr_low:.2f}%")
print(f"Diferen√ßa: {wr_high - wr_low:.2f}pp")

if wr_high - wr_low > 10:
    print("‚úÖ Filtro ADX melhora performance - Implementar!")
else:
    print("‚ùå Filtro ADX n√£o agrega valor - Ignorar")
```

**Implementa√ß√£o**:
```python
# Em feature_calculator.py
from ta.trend import ADXIndicator

def add_adx(df):
    adx_indicator = ADXIndicator(df['high'], df['low'], df['close'], window=14)
    df['adx'] = adx_indicator.adx()
    return df

# Em forward_testing.py
if prediction['confidence'] >= threshold and df['adx'].iloc[-1] > 25:
    await self._execute_trade(prediction, current_price)
else:
    logger.info(f"Trade ignorado - ADX={df['adx'].iloc[-1]:.2f} < 25")
```

**Resultado Esperado**:
- Decis√£o data-driven sobre implementar filtro ADX
- Se implementado: Win rate > 50%

---

## üéØ SPRINT 3: Re-treinamento com Melhorias (Semana 3) üÜï

**Objetivo**: Re-treinar modelo incorporando learnings dos Sprints 1-2

**Status**: üü° CONDICIONAL - S√≥ executar se acur√°cia atual < 50%

**Pr√©-condi√ß√£o**: Ter identificado padr√µes claros de falha no Sprint 1.2

---

### 3.1 Feature Selection via SHAP
**Objetivo**: Remover features irrelevantes que podem causar overfitting

**Contexto**: Fase 0.2 mostrou que top 20 features representam 80% da import√¢ncia

**A√ß√£o**:
- [ ] Carregar modelo atual
- [ ] Calcular SHAP values para todas as 65 features
- [ ] Identificar features com SHAP mean < 0.01 (ru√≠do)
- [ ] Criar novo dataset com apenas top 40 features
- [ ] Re-treinar modelo e comparar performance

**C√≥digo**:
```python
import shap

# Calcular SHAP
explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_test)

# Import√¢ncia m√©dia
if isinstance(shap_values, list):
    shap_values = shap_values[1]  # Classe PRICE_UP

feature_importance = np.abs(shap_values).mean(axis=0)
importance_df = pd.DataFrame({
    'feature': X_test.columns,
    'importance': feature_importance
}).sort_values('importance', ascending=False)

# Selecionar top 40
top_features = importance_df.head(40)['feature'].tolist()

print(f"Features selecionadas: {len(top_features)}")
print(f"Import√¢ncia acumulada: {importance_df.head(40)['importance'].sum() / importance_df['importance'].sum() * 100:.1f}%")

# Re-treinar com features selecionadas
X_train_selected = X_train[top_features]
X_test_selected = X_test[top_features]

model_v2 = xgb.XGBClassifier(...)
model_v2.fit(X_train_selected, y_train)
```

**Crit√©rio de Sucesso**: Acur√°cia melhora OU modelo fica mais r√°pido sem perder acur√°cia

---

### 3.2 Hyperparameter Tuning (Grid Search)
**Objetivo**: Encontrar hiperpar√¢metros √≥timos para modelo multi-class

**Contexto**: Par√¢metros atuais foram escolhidos empiricamente

**A√ß√£o**:
- [ ] Definir grid de par√¢metros a testar
- [ ] Usar cross-validation (5 folds) para cada combina√ß√£o
- [ ] Encontrar combina√ß√£o com melhor F1-score (macro)
- [ ] Re-treinar modelo final com best params

**Grid de Par√¢metros**:
```python
from sklearn.model_selection import GridSearchCV

param_grid = {
    'max_depth': [4, 6, 8],
    'learning_rate': [0.03, 0.05, 0.07],
    'n_estimators': [200, 300, 400],
    'min_child_weight': [1, 3, 5],
    'subsample': [0.7, 0.8, 0.9],
    'colsample_bytree': [0.7, 0.8, 0.9]
}

grid_search = GridSearchCV(
    estimator=xgb.XGBClassifier(objective='multi:softmax', num_class=3),
    param_grid=param_grid,
    scoring='f1_macro',
    cv=5,
    n_jobs=-1,
    verbose=2
)

grid_search.fit(X_train, y_train)

print("Best params:", grid_search.best_params_)
print("Best F1-score:", grid_search.best_score_)

# Treinar modelo final
best_model = grid_search.best_estimator_
```

**Resultado Esperado**: Acur√°cia > 40% (atualmente 33.25%)

---

### 3.3 Ensemble de Modelos (OPCIONAL)
**Objetivo**: Combinar m√∫ltiplos modelos para melhorar robustez

**S√≥ executar SE**: Acur√°cia do modelo √∫nico ainda < 45% ap√≥s 3.1 e 3.2

**A√ß√£o**:
- [ ] Treinar LightGBM com mesmo dataset
- [ ] Treinar Random Forest com mesmo dataset
- [ ] Criar Voting Classifier (soft voting)
- [ ] Validar se ensemble > modelo √∫nico

**C√≥digo**:
```python
from sklearn.ensemble import VotingClassifier
import lightgbm as lgb
from sklearn.ensemble import RandomForestClassifier

# Treinar modelos individuais
xgb_model = xgb.XGBClassifier(...)
lgbm_model = lgb.LGBMClassifier(...)
rf_model = RandomForestClassifier(n_estimators=300, max_depth=10)

xgb_model.fit(X_train, y_train)
lgbm_model.fit(X_train, y_train)
rf_model.fit(X_train, y_train)

# Criar ensemble
ensemble = VotingClassifier(
    estimators=[
        ('xgb', xgb_model),
        ('lgbm', lgbm_model),
        ('rf', rf_model)
    ],
    voting='soft',
    weights=[2, 1, 1]  # XGBoost tem peso maior
)

ensemble.fit(X_train, y_train)

# Comparar acur√°cia
acc_xgb = accuracy_score(y_test, xgb_model.predict(X_test))
acc_ensemble = accuracy_score(y_test, ensemble.predict(X_test))

print(f"XGBoost alone: {acc_xgb*100:.2f}%")
print(f"Ensemble: {acc_ensemble*100:.2f}%")
print(f"Melhoria: {(acc_ensemble - acc_xgb)*100:.2f}pp")
```

**Crit√©rio**: S√≥ usar ensemble se melhoria > 5pp

---

## üéØ SPRINT 4: Valida√ß√£o Robusta (Semana 4) ‚úÖ

**Objetivo**: Garantir que modelo √© robusto e n√£o overfitted

**Status**: üî¥ CR√çTICO - Essencial antes de produ√ß√£o

---

### 4.1 Walk-Forward Analysis
**Objetivo**: Validar consist√™ncia do modelo ao longo do tempo

**Problema**: Modelo pode estar overfitted nos dados de treino

**A√ß√£o**:
- [ ] Dividir 6 meses de dados em 10 per√≠odos (janelas de 18 dias)
- [ ] Para cada per√≠odo:
  - Treinar nos 5 per√≠odos anteriores
  - Testar no per√≠odo seguinte
  - Registrar win rate, Sharpe, Profit Factor
- [ ] Validar se win rate > 45% em PELO MENOS 8/10 per√≠odos

**C√≥digo**:
```python
import numpy as np
from datetime import timedelta

# Dividir dataset em 10 per√≠odos
periods = np.array_split(df, 10)
results = []

for i in range(5, len(periods)):
    # Train: per√≠odos 0 a i-1
    train_periods = periods[:i]
    train_df = pd.concat(train_periods)

    # Test: per√≠odo i
    test_df = periods[i]

    # Treinar modelo
    X_train = train_df[feature_columns]
    y_train = train_df['label']
    X_test = test_df[feature_columns]
    y_test = test_df['label']

    model = xgb.XGBClassifier(...)
    model.fit(X_train, y_train)

    # Avaliar
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    win_rate = (y_test == y_pred).mean() * 100

    results.append({
        'period': i,
        'accuracy': acc,
        'win_rate': win_rate,
        'samples': len(test_df)
    })

    print(f"Period {i}: Accuracy={acc*100:.2f}%, WR={win_rate:.2f}%")

# An√°lise de consist√™ncia
results_df = pd.DataFrame(results)
consistency = (results_df['win_rate'] > 45).sum() / len(results_df) * 100

print(f"\nConsist√™ncia (WR>45%): {consistency:.0f}% dos per√≠odos")
print(f"WR m√©dio: {results_df['win_rate'].mean():.2f}%")
print(f"Desvio padr√£o: {results_df['win_rate'].std():.2f}%")
```

**Crit√©rios de Aprova√ß√£o**:
- Win rate > 45% em 80% dos per√≠odos
- Desvio padr√£o < 10%
- Sem per√≠odo com accuracy < 30%

**Se FALHAR**: Modelo est√° overfitted - retornar ao Sprint 3

---

### 4.2 Monte Carlo Simulation
**Objetivo**: Entender worst-case scenario de drawdown

**A√ß√£o**:
- [ ] Simular 1000 sequ√™ncias aleat√≥rias de trades hist√≥ricos
- [ ] Para cada simula√ß√£o, calcular:
  - Max Drawdown
  - Ruin probability (capital < $5k)
  - Sharpe Ratio
- [ ] Calcular percentil 5% de drawdown (worst case)
- [ ] Validar que 95% das simula√ß√µes t√™m DD < 30%

**C√≥digo**:
```python
import random

n_simulations = 1000
max_drawdowns = []
ruin_count = 0

for sim in range(n_simulations):
    # Embaralhar ordem dos trades
    simulated_trades = random.sample(list(df['profit_loss']), len(df))

    # Calcular equity curve
    capital = 10000
    equity = [capital]

    for pnl in simulated_trades:
        capital += pnl
        equity.append(capital)

        if capital < 5000:
            ruin_count += 1
            break

    # Calcular max drawdown
    peak = equity[0]
    max_dd = 0
    for val in equity:
        if val > peak:
            peak = val
        dd = (peak - val) / peak * 100
        if dd > max_dd:
            max_dd = dd

    max_drawdowns.append(max_dd)

# An√°lise de risco
print(f"Max Drawdown m√©dio: {np.mean(max_drawdowns):.2f}%")
print(f"Max DD percentil 95%: {np.percentile(max_drawdowns, 95):.2f}%")
print(f"Probabilidade de ru√≠na: {ruin_count/n_simulations*100:.2f}%")

# Gr√°fico de distribui√ß√£o
plt.hist(max_drawdowns, bins=50)
plt.xlabel('Max Drawdown (%)')
plt.ylabel('Frequ√™ncia')
plt.title('Distribui√ß√£o de Max Drawdown (1000 simula√ß√µes)')
plt.axvline(np.percentile(max_drawdowns, 95), color='r', linestyle='--', label='P95')
plt.legend()
plt.show()
```

**Crit√©rios de Aprova√ß√£o**:
- Percentil 95 de DD < 30%
- Probabilidade de ru√≠na < 5%
- DD m√©dio < 20%

---

### 4.3 Stress Testing
**Objetivo**: Validar que sistema sobrevive a eventos extremos

**Cen√°rios de Teste**:
1. **Crash -20%**: Pre√ßo cai 20% em 1 hora
2. **Volatilidade Spike**: ATR dobra repentinamente
3. **Gap de Pre√ßo**: Gap de 5% overnight
4. **Sequ√™ncia de Perdas**: 10 perdas consecutivas

**A√ß√£o**:
- [ ] Simular cada cen√°rio
- [ ] Verificar se circuit breaker (se implementado) funciona
- [ ] Validar que sistema n√£o quebra (erros, crashes)
- [ ] Calcular impact no capital

**C√≥digo de Simula√ß√£o**:
```python
def simulate_crash(df, crash_pct=-20):
    """Simula crash de -20% em 1 hora"""
    crash_df = df.copy()
    # Reduzir pre√ßos em 20%
    crash_df['close'] *= (1 + crash_pct/100)
    crash_df['high'] *= (1 + crash_pct/100)
    crash_df['low'] *= (1 + crash_pct/100)

    # Executar forward testing no cen√°rio de crash
    # ... (c√≥digo de simula√ß√£o)

    return impact_on_capital

# Testar todos os cen√°rios
scenarios = {
    'crash_20pct': simulate_crash(df, -20),
    'volatility_spike': simulate_volatility_spike(df),
    'price_gap': simulate_gap(df, 5),
    'loss_streak': simulate_loss_streak(df, 10)
}

print("Stress Test Results:")
for scenario, impact in scenarios.items():
    print(f"{scenario}: Capital impact = {impact:.2f}%")
```

**Crit√©rios de Aprova√ß√£o**:
- Sistema n√£o quebra em nenhum cen√°rio
- Capital loss < 40% no pior cen√°rio
- Circuit breaker ativa (se implementado)

---

## üìä Crit√©rios Finais para Produ√ß√£o

Antes de considerar o sistema PRONTO para produ√ß√£o real (capital real), TODOS os crit√©rios devem ser atendidos:

### ‚úÖ Sprint 1 (Valida√ß√£o)
- [x] Modelo prev√™ as 3 classes (n√£o >70% em uma)
- [ ] Win rate > 40% em 50+ trades
- [ ] Timeout rate < 30%
- [ ] Sharpe Ratio > 1.0

### ‚úÖ Sprint 2 (Otimiza√ß√£o)
- [ ] SL/TP otimizados via grid search
- [ ] Profit Factor > 1.5
- [ ] Max Drawdown < 20%

### ‚úÖ Sprint 3 (Re-treinamento - OPCIONAL)
- [ ] Acur√°cia > 45% (se re-treinado)
- [ ] Feature selection reduz overfitting

### ‚úÖ Sprint 4 (Valida√ß√£o Robusta)
- [ ] Walk-Forward: Consist√™ncia > 80%
- [ ] Monte Carlo: P95 DD < 30%
- [ ] Stress Tests: Sistema sobrevive 100%

**Se TODOS os crit√©rios forem atendidos**: Sistema APROVADO para produ√ß√£o com capital pequeno ($100-$500 inicial)

**Se ALGUM crit√©rio FALHAR**: Retornar ao Sprint correspondente e corrigir problema raiz antes de prosseguir.

---

## üîÑ Roadmap de Execu√ß√£o Sugerido

```
Semana 1: Sprint 1 (Valida√ß√£o) ‚Üí Gera baseline de performance real
Semana 2: Sprint 2 (Otimiza√ß√£o) ‚Üí Melhora par√¢metros baseado em dados
Semana 3: Sprint 3 (Re-treino - SE necess√°rio) ‚Üí Melhora modelo
Semana 4: Sprint 4 (Valida√ß√£o Robusta) ‚Üí Garante robustez

Total: 4 semanas at√© decis√£o de produ√ß√£o
```

**Marco Final**: Sistema em produ√ß√£o com capital real ($100 inicial) em modo observa√ß√£o por 1 semana antes de escalar.
