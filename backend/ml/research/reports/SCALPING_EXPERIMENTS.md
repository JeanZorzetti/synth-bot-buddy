# Experimentos de Otimiza√ß√£o - Scalping V100 M5

**Data:** 18/12/2025
**Objetivo:** Atingir 60%+ win rate em scalping com V100 M5
**Baseline:** 50.9% win rate (TP 0.2% / SL 0.1%, XGBoost 50 trials)

---

## üìä Contexto

### Problema Identificado

Ap√≥s o treinamento inicial do modelo XGBoost com Optuna (50 trials), obtivemos:

| M√©trica | Valor | Meta | Status |
|---------|-------|------|--------|
| **Win Rate (Test)** | 50.9% | 60%+ | ‚ùå N√£o atingida |
| **F1-score** | 0.498 | 0.65+ | ‚ùå N√£o atingida |
| **Accuracy (tradeable)** | 51.6% | 60%+ | ‚ùå N√£o atingida |

### An√°lise da Falha

**Confusion Matrix (Test Set - LONG/SHORT apenas):**

```
Predi√ß√£o:    LONG    SHORT
Real LONG:   3166    1983    = 61.5% acerto
Real SHORT:  2717    1717    = 38.7% acerto
```

**Problemas identificados:**

1. **Vi√©s para LONG**: Modelo prev√™ SHORT com apenas 38.7% de acerto
2. **Features insuficientes**: Melhoria de apenas +0.6% sobre baseline (50.3% ‚Üí 50.9%)
3. **TP/SL muito apertado?**: 0.2% TP / 0.1% SL pode gerar muito ru√≠do em M5
4. **Hiperpar√¢metros sub√≥timos**: 50 trials podem ser insuficientes

---

## üß™ Experimentos Propostos

### Experimento A: TP/SL Relaxado

**Hip√≥tese:** TP/SL mais largo (0.3%/0.15%) reduz ru√≠do e aumenta win rate base

**Configura√ß√£o:**
- **TP:** 0.3% (antes: 0.2%)
- **SL:** 0.15% (antes: 0.1%)
- **R:R:** 1:2 (mantido)
- **Modelo:** XGBoost
- **Optuna trials:** 50

**Expectativa:** Win rate base pode melhorar de 50.3% ‚Üí 55-58%, dando margem para ML atingir 60%+

**Custo:** ~5-7 minutos (labeling + training)

---

### Experimento B: Ensemble de Modelos

**Hip√≥tese:** Combinar XGBoost + LightGBM + CatBoost aumenta robustez e reduz vi√©s

**Configura√ß√£o:**
- **Modelos:** XGBoost, LightGBM, CatBoost
- **Voting:** Soft voting (m√©dia de probabilidades)
- **Dataset:** Original (TP 0.2% / SL 0.1%)
- **Hiperpar√¢metros:** Melhores do baseline para cada modelo

**Literatura:**
- Ensemble costuma adicionar +5-10% de performance sobre modelo √∫nico
- Reduz overfitting e vi√©s de modelo espec√≠fico

**Expectativa:** Win rate 55-60% (pode atingir meta!)

**Custo:** ~8-10 minutos (treinar 3 modelos)

---

### Experimento C: Optuna com 100 Trials

**Hip√≥tese:** 50 trials foram insuficientes, 100 trials achar√£o hiperpar√¢metros melhores

**Configura√ß√£o:**
- **Modelo:** XGBoost
- **Optuna trials:** 100 (2x mais explora√ß√£o)
- **Dataset:** Original (TP 0.2% / SL 0.1%)
- **Early stopping:** 20 rounds

**Expectativa:** Win rate 52-56% (melhoria marginal)

**Custo:** ~6-8 minutos (2x mais trials)

---

## üìà Metodologia de Avalia√ß√£o

### M√©tricas de Compara√ß√£o

Para cada experimento, avaliaremos:

1. **Win Rate (prim√°ria):** % de trades corretos (LONG/SHORT) no test set
2. **F1-score:** M√©dia harm√¥nica de precision/recall
3. **Accuracy tradeable:** Accuracy ignorando NO_TRADE
4. **Confusion matrix:** Distribui√ß√£o de acertos LONG vs SHORT
5. **Feature importance:** Top 10 features mais importantes

### Crit√©rios de Sucesso

| Crit√©rio | Valor |
|----------|-------|
| **Meta ATINGIDA** | Win rate ‚â• 60% |
| **Meta PARCIAL** | Win rate 55-60% |
| **Melhoria MARGINAL** | Win rate 51-55% |
| **SEM melhoria** | Win rate < 51% |

### Decis√£o P√≥s-Experimentos

**Se meta atingida (‚â•60%):**
‚Üí Prosseguir para Backtesting completo (3 meses out-of-sample)

**Se meta parcial (55-60%):**
‚Üí Considerar Feature Engineering avan√ßada (order flow, tape reading)
‚Üí Ou aceitar 55-60% e testar em forward testing

**Se sem melhoria (<55%):**
‚Üí Reavaliar estrat√©gia:
  - Testar timeframe M15 (mais est√°vel)
  - Testar outros ativos sint√©ticos (BOOM/CRASH)
  - Considerar estrat√©gia de revers√£o √† m√©dia ao inv√©s de momentum

---

## üî¨ Resultados dos Experimentos

### Baseline (Refer√™ncia)

```
Configura√ß√£o:
  - TP/SL: 0.2% / 0.1%
  - Modelo: XGBoost
  - Optuna trials: 50
  - Dataset: 51,789 candles

Resultados:
  - Win rate: 50.9%
  - F1-score: 0.498
  - Accuracy: 51.6%
  - Status: ‚ùå Meta n√£o atingida
```

---

### Experimento A: TP/SL 0.3% / 0.15%

**Status:** ‚úÖ CONCLU√çDO

```
Win rate: 51.2%
F1-score: 0.512
Accuracy: 51.2%
Melhoria sobre baseline: +0.3pp

Melhores hiperpar√¢metros:
  - max_depth: 8
  - learning_rate: 0.291
  - n_estimators: 107
  - min_child_weight: 4
  - subsample: 0.99
  - colsample_bytree: 0.88
  - gamma: 2.09
  - reg_alpha: 1.13
  - reg_lambda: 1.98
```

**An√°lise:**
- [x] Win rate base melhorou? **SIM (+0.3pp)**
- [x] Vi√©s LONG/SHORT foi reduzido? **Melhoria marginal**
- [ ] Meta de 60% atingida? **N√ÉO (faltam 8.8pp)**

---

### Experimento B: Ensemble (XGB + LGB + CAT)

**Status:** ‚ùå FALHOU

```
Erro: 'VotingClassifier' object has no attribute 'le_'

Causa: Problema na implementa√ß√£o do VotingClassifier
       Os modelos individuais foram treinados mas o ensemble
       n√£o foi fitted corretamente antes da predi√ß√£o.

Impacto: Experimento B n√£o possui resultados v√°lidos.
```

**An√°lise:**
- [ ] Ensemble superou modelo √∫nico? **N/A (falhou)**
- [ ] Redu√ß√£o de overfitting? **N/A (falhou)**
- [ ] Meta de 60% atingida? **N/A (falhou)**

---

### Experimento C: Optuna 100 Trials

**Status:** ‚úÖ CONCLU√çDO

```
Win rate: 51.0%
F1-score: 0.494
Accuracy: 51.0%
Melhoria sobre baseline: +0.1pp

Melhores hiperpar√¢metros:
  - max_depth: 7
  - learning_rate: 0.122
  - n_estimators: 421
  - min_child_weight: 4
  - subsample: 0.64
  - colsample_bytree: 0.72
  - gamma: 0.86
  - reg_alpha: 1.50
  - reg_lambda: 0.56
```

**An√°lise:**
- [x] Hiperpar√¢metros melhoraram? **SIM (mais conservadores)**
- [ ] Ganho justifica 2x mais tempo? **N√ÉO (apenas +0.1pp)**
- [ ] Meta de 60% atingida? **N√ÉO (faltam 9.0pp)**

---

## üìä Compara√ß√£o Final

### Ranking por Win Rate

| Posi√ß√£o | Experimento | Win Rate | F1-score | Melhoria |
|---------|-------------|----------|----------|----------|
| Baseline | XGB 50 trials (0.2/0.1) | 50.9% | 0.498 | - |
| ü•á 1¬∫ | Exp A: TP/SL 0.3/0.15 | 51.2% | 0.512 | +0.3pp |
| ü•à 2¬∫ | Exp C: 100 trials | 51.0% | 0.494 | +0.1pp |
| ‚ùå 3¬∫ | Exp B: Ensemble | N/A | N/A | FALHOU |

### Melhor Experimento

**Vencedor:** Experimento A (TP/SL Relaxado 0.3% / 0.15%)

**Justificativa:**
- Win rate: **51.2%**
- Melhoria sobre baseline: **+0.3pp**
- Vi√©s LONG/SHORT: **Melhoria marginal**
- Status da meta: **‚ùå N√ÉO ATINGIDA (faltam 8.8pp para 60%)**

**Conclus√£o Cr√≠tica:**
Todos os experimentos falharam em atingir a meta de 60% win rate. A melhoria m√°xima foi de apenas 0.3 pontos percentuais, sugerindo que:

1. **Features atuais s√£o insuficientes** para discriminar setups lucrativos em V100 M5
2. **TP/SL pode estar inadequado** para a volatilidade real do ativo
3. **Scalping em M5 pode n√£o ser vi√°vel** com a abordagem atual de ML supervisionado

**Pr√≥ximas a√ß√µes necess√°rias:**
- Feature Engineering Avan√ßada (order flow, tape reading, volume profile)
- Testar M15/M30 (timeframes mais est√°veis)
- Considerar outros ativos (BOOM/CRASH com padr√µes mais claros)
- Avaliar estrat√©gias alternativas (mean reversion, grid trading)

---

## üéØ Pr√≥ximos Passos

### Se Meta Atingida (‚â•60%)

1. ‚úÖ **Salvar modelo vencedor**
2. ‚è≥ Criar script de backtesting completo
3. ‚è≥ Executar backtest (3 meses out-of-sample)
4. ‚è≥ Analisar drawdown, sharpe ratio, profit factor
5. ‚è≥ Se backtest OK ‚Üí Forward testing (1 semana paper trading)
6. ‚è≥ Se forward OK ‚Üí Trading real ($100 inicial)

### Se Meta Parcial (55-60%)

1. ‚è≥ Feature Engineering Avan√ßada:
   - Volume profile
   - Order flow imbalance
   - Tape reading features
   - Delta cumulativo
   - Absor√ß√£o de ordens

2. ‚è≥ Testar ensemble avan√ßado:
   - Stacking (meta-modelo)
   - Blending com pesos otimizados

3. ‚è≥ Considerar aceitar 55-60% e testar em forward

### Se Sem Melhoria (<55%)

1. ‚è≥ Testar timeframe M15 (mais est√°vel, menos ru√≠do)
2. ‚è≥ Testar outros ativos:
   - BOOM300N (spikes para cima)
   - CRASH300N (spikes para baixo)
   - Volatility 25 (m√©dia volatilidade)
3. ‚è≥ Reavaliar estrat√©gia:
   - Mean reversion ao inv√©s de momentum
   - Grid trading
   - Martingale adaptativo

---

## üìö Refer√™ncias

### Literatura sobre Ensemble

- Zhou, Z. H. (2012). *Ensemble Methods: Foundations and Algorithms*
- Kaggle competitions: Ensemble adiciona ~5-10% performance
- XGBoost + LightGBM + CatBoost = combina√ß√£o padr√£o em competi√ß√µes

### TP/SL em Scalping

- Mercado scalping M5: TP 0.3-0.5%, SL 0.15-0.25%
- R:R 1:2 considerado m√≠nimo aceit√°vel
- Win rate m√≠nimo 55-60% para lucratividade

### Optuna Trials

- 50 trials: explora√ß√£o b√°sica
- 100 trials: explora√ß√£o m√©dia (recomendado)
- 200+ trials: explora√ß√£o extensiva (diminishing returns)

---

## üìù Notas T√©cnicas

### Infraestrutura

- **CPU:** Usado para treinamento (XGBoost tree_method='hist')
- **RAM:** ~2GB usage durante training
- **Tempo total:** ~20-25 minutos para os 3 experimentos

### Reprodutibilidade

Todos os experimentos usam `random_state=42` para garantir reprodutibilidade.

Seeds fixas:
- XGBoost: `random_state=42`
- LightGBM: `random_state=42`
- CatBoost: `random_state=42`
- Train/test split: `random_state=42`

### Datasets

```
backend/ml/research/data/
‚îú‚îÄ‚îÄ 1HZ100V_5min_180days.csv                    # Raw data
‚îú‚îÄ‚îÄ 1HZ100V_5min_180days_features.csv           # + 62 features
‚îú‚îÄ‚îÄ 1HZ100V_5min_180days_labeled.csv            # + labels (0.2/0.1)
‚îî‚îÄ‚îÄ 1HZ100V_5min_labeled_exp_a.csv              # + labels (0.3/0.15)
```

### Modelos Salvos

```
backend/ml/research/models/
‚îú‚îÄ‚îÄ scalping_xgboost_model.pkl                  # Baseline
‚îú‚îÄ‚îÄ experiment_a_model.pkl                      # Exp A
‚îú‚îÄ‚îÄ experiment_b_ensemble.pkl                   # Exp B
‚îî‚îÄ‚îÄ experiment_c_model.pkl                      # Exp C
```

---

**Autor:** Claude Sonnet 4.5
**Data √∫ltima atualiza√ß√£o:** 18/12/2025 19:15 UTC
**Vers√£o:** 1.0
