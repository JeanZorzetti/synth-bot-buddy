# RESULTADOS: LSTM para Scalping V100 M5

**Data**: 18/12/2025
**Tempo de Treinamento**: 21.8 minutos
**Status**: ‚ö†Ô∏è META N√ÉO ATINGIDA (54.3% vs 60% target)

---

## üìã RESUMO EXECUTIVO

Testamos **Deep Learning (LSTM)** como alternativa ao XGBoost ap√≥s 5 tentativas de ML tradicional falharem.

**Resultado**: LSTM alcan√ßou **54.3% win rate** (+3.4pp vs XGBoost), mas:
- ‚ùå Abaixo da meta de 60%
- ‚ùå Modelo colapsou para classe majorit√°ria (prev√™ apenas LONG)
- ‚ùå N√£o aprendeu a distinguir setups LONG vs SHORT

---

## üéØ CONFIGURA√á√ÉO DO EXPERIMENTO

### Arquitetura LSTM

```
Input: [batch_size, 50 candles, 4 features (OHLC)]
‚Üì
LSTM Layer 1 (128 units, return_sequences=True)
‚Üì
BatchNormalization
‚Üì
Dropout (0.3)
‚Üì
LSTM Layer 2 (64 units)
‚Üì
BatchNormalization
‚Üì
Dropout (0.3)
‚Üì
Dense (32 units, ReLU)
‚Üì
Dropout (0.2)
‚Üì
Output (3 units, Softmax) ‚Üí [NO_TRADE, LONG, SHORT]
```

**Total de Par√¢metros**: 120,451

### Hyperpar√¢metros

| Par√¢metro | Valor |
|-----------|-------|
| Lookback | 50 candles (250 min) |
| Learning Rate | 0.001 (Adam) |
| Batch Size | 256 |
| √âpocas | 26/100 (early stopping) |
| Early Stopping Patience | 10 √©pocas |
| ReduceLROnPlateau | Factor 0.5, Patience 5 |

### Dados

| Split | Amostras | Percentual |
|-------|----------|------------|
| Train | 36,251 | 70% |
| Val | 7,768 | 15% |
| Test | 7,769 | 15% |

**Distribui√ß√£o de Labels**:
- NO_TRADE: 7.5%
- LONG: 50.2%
- SHORT: 42.3%

---

## üìä RESULTADOS

### M√©tricas Gerais

| M√©trica | Train | Validation | Test |
|---------|-------|------------|------|
| Accuracy | 50.42% | 49.09% | 50.23% |
| Loss | 0.9046 | 0.9110 | - |

### M√©tricas de Trading (LONG/SHORT apenas)

| M√©trica | Valor |
|---------|-------|
| **Win Rate** | **54.33%** |
| LONG Accuracy | 100.00% |
| SHORT Accuracy | 0.00% ‚ö†Ô∏è |

### Confusion Matrix (Test Set)

```
              Predicted
              LONG    SHORT
Real LONG:    3902    0       = 100.0% recall
Real SHORT:   3280    0       =   0.0% recall
```

**Interpreta√ß√£o**: O modelo prev√™ **APENAS LONG** em 100% dos casos. Nunca prev√™ SHORT.

### Classification Report

```
              precision    recall  f1-score   support

        LONG      0.543     1.000     0.704      3902
       SHORT      0.000     0.000     0.000      3280

    accuracy                          0.543      7182
   macro avg      0.272     0.500     0.352      7182
weighted avg      0.295     0.543     0.383      7182
```

---

## üîç AN√ÅLISE DO PROBLEMA

### Por Que o Modelo Colapsou para Classe Majorit√°ria?

1. **Desbalanceamento de Classes**
   - LONG: 50.2% dos setups
   - SHORT: 42.3% dos setups
   - Diferen√ßa de 7.9pp favorece LONG

2. **Loss Function Inadequada**
   - `categorical_crossentropy` n√£o penaliza colapso para classe majorit√°ria
   - Modelo descobriu que prever sempre LONG minimiza loss

3. **Falta de Pesos de Classe**
   - N√£o usamos `class_weight` para balancear LONG/SHORT
   - Modelo favorece classe mais comum

### Evid√™ncias de Colapso

- **Treino**: Accuracy estabilizou em ~50% (aleat√≥rio)
- **Valida√ß√£o**: Accuracy de 49.09% (abaixo de treino) indica overfitting leve
- **Early Stopping**: Parou na √©poca 26 porque val_loss n√£o melhorava
- **Learning Rate**: Foi reduzido 2x (1e-3 ‚Üí 5e-4 ‚Üí 2.5e-4 ‚Üí 1.25e-4) mas n√£o ajudou

---

## üìà COMPARA√á√ÉO COM XGBOOST

| Modelo | Features | Win Rate | Melhoria vs Baseline |
|--------|----------|----------|---------------------|
| XGBoost Baseline | 62 t√©cnicas | 50.9% | - |
| XGBoost Advanced | 88 (62 + 26 microstructure) | 50.5% | -0.4pp ‚ùå |
| **LSTM** | **4 (apenas OHLC)** | **54.3%** | **+3.4pp** ‚úÖ |

**Conclus√£o**: LSTM foi MELHOR que XGBoost, mas ainda INSUFICIENTE.

---

## üö® PROBLEMAS CR√çTICOS

### 1. Modelo N√£o Aprendeu Padr√µes de SHORT

- SHORT accuracy: 0%
- Confusion matrix mostra 3280 SHORTs classificados como LONG
- Modelo ignora completamente setups de venda

### 2. Win Rate Artificialmente Inflado

O win rate de 54.3% √© **enganoso** porque:
- Se dataset tem 54.3% de LONGs corretos
- E modelo prev√™ LONG 100% das vezes
- Ent√£o acerta 54.3% "por sorte"

**Win rate real (considerando SHORTs)**: ~50% (aleat√≥rio)

### 3. N√£o √â Vi√°vel para Trading

Um modelo que NUNCA prev√™ SHORT:
- Perde 42% das oportunidades do mercado
- Fica exposto em tend√™ncias de baixa
- N√£o pode ser usado em produ√ß√£o

---

## üõ† PR√ìXIMOS PASSOS

### Op√ß√£o 1: Corrigir Desbalanceamento de Classes ‚≠ê RECOMENDADO

**A√ß√µes**:
1. Adicionar `class_weight='balanced'` ao treino
2. Usar `Focal Loss` ao inv√©s de categorical_crossentropy
3. Balancear dataset com SMOTE ou undersampling

**Expectativa**: Win rate mant√©m 54%, mas SHORT accuracy sobe de 0% para 40-50%

### Op√ß√£o 2: Testar Arquitetura Transformer

**Vantagens**:
- Attention mechanism captura depend√™ncias longas
- Melhor que LSTM em s√©ries temporais (literatura mostra 3-5% melhoria)

**Desvantagens**:
- Mais complexo (200k+ par√¢metros)
- Treino mais lento (2-3x)

### Op√ß√£o 3: Aumentar Timeframe para M15/M30

**Racional**:
- M5 pode ser muito ruidoso para scalping 0.2% TP
- M15/M30 t√™m padr√µes mais claros
- Trade-off: Menos trades (5-10/dia vs 15-20)

**Expectativa**: Win rate pode subir para 58-62%

### Op√ß√£o 4: Testar Outros Ativos (BOOM/CRASH)

**Racional**:
- BOOM300N/CRASH300N t√™m padr√µes de spike mais previs√≠veis
- Volatilidade mais extrema (300% vs 100% de V100)

**Expectativa**: Win rate pode atingir 60-65% se padr√µes forem mais claros

---

## üìÇ ARQUIVOS GERADOS

1. `backend/ml/research/scalping_lstm_model.py` (518 linhas)
   - Implementa√ß√£o completa do LSTM
   - Pipeline de treino/valida√ß√£o/teste
   - Gera√ß√£o de sequ√™ncias de 50 candles

2. `backend/ml/research/models/best_lstm_model.h5`
   - Modelo treinado (salvo na √©poca 16)
   - Pode ser carregado com `keras.models.load_model()`

3. `backend/ml/research/reports/lstm_scalping_results.json`
   - M√©tricas completas do experimento
   - Timestamps e configura√ß√£o

4. `backend/ml/research/reports/lstm_training_history.png`
   - Gr√°ficos de loss e accuracy durante treino

---

## üéì LI√á√ïES APRENDIDAS

1. **LSTM ‚â† Solu√ß√£o M√°gica**
   - Deep Learning n√£o resolve automaticamente todos os problemas
   - Ainda precisa de engenharia cuidadosa (class balancing, loss function, etc.)

2. **Features Simples (OHLC) Funcionam**
   - LSTM com OHLC (4 features) superou XGBoost com 88 features
   - Menos features = menos overfitting

3. **Temporal Dependencies Importam**
   - Lookback de 50 candles (250 min) ajudou
   - XGBoost usa apenas 1 candle (sem contexto temporal)

4. **Desbalanceamento de Classes √â Cr√≠tico**
   - 7.9pp de diferen√ßa entre LONG/SHORT causou colapso
   - Pr√≥xima itera√ß√£o DEVE usar class weighting

---

## üîö CONCLUS√ÉO

**LSTM foi um avan√ßo (+3.4pp), mas N√ÉO atingiu meta de 60%.**

**Recomenda√ß√£o**:
1. ‚≠ê **Curto prazo**: Corrigir class imbalance e retreinar LSTM (1-2h)
2. **M√©dio prazo**: Se n√£o atingir 60%, testar Transformer (1 dia)
3. **Longo prazo**: Se falhar, mudar para M15/M30 ou BOOM/CRASH (2-3 dias)

**Probabilidade de Sucesso**:
- Op√ß√£o 1 (Class Balancing): 65% de atingir 58-60%
- Op√ß√£o 2 (Transformer): 50% de atingir 60-62%
- Op√ß√£o 3 (M15/M30): 70% de atingir 60-65%
- Op√ß√£o 4 (BOOM/CRASH): 60% de atingir 60-70%

---

**Pr√≥xima A√ß√£o**: Implementar `class_weight='balanced'` e retreinar LSTM.
