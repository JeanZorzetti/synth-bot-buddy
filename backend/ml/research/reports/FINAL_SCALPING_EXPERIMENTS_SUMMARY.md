# RESUMO FINAL: Experimentos de Scalping V100 M5

**Data**: 19/12/2025
**Objetivo**: Atingir 60% win rate para scalping com TP 0.2%, SL 0.1%
**Status**: âŒ META NÃƒO ATINGIDA em nenhum dos 11 experimentos

---

## ğŸ“Š TODOS OS EXPERIMENTOS (CronolÃ³gico)

### FASE 1: XGBoost (ML Tradicional)

| Experimento | Features | Win Rate | Status |
|-------------|----------|----------|--------|
| **Baseline** | 62 tÃ©cnicas | 50.9% | âŒ Falhou |
| **Experimento A** | TP/SL relaxado | 51.2% | âŒ Falhou |
| **Experimento B** | Ensemble (3 modelos) | Falhou | âŒ NÃ£o convergiu |
| **Experimento C** | 100 trials Optuna | 51.0% | âŒ Falhou |
| **Advanced Features** | 88 (62 + 26 microstructure) | 50.5% | âŒ Pior |

**ConclusÃ£o XGBoost**: Tree-based models nÃ£o aprendem padrÃµes temporais. Max 51.2% win rate.

---

### FASE 2: Deep Learning - LSTM Baseline

| Modelo | Features | Win Rate | LONG Acc | SHORT Acc | Status |
|--------|----------|----------|----------|-----------|--------|
| **LSTM** | 4 OHLC | 54.3% | 100.0% | 0.0% | âš ï¸ Colapso |

**Detalhes**:
- Arquitetura: 2 LSTM layers (128, 64) + Dense
- ParÃ¢metros: 120,451
- Treino: 26 Ã©pocas, early stopping
- **Problema**: Modelo colapsa para classe majoritÃ¡ria (prevÃª apenas LONG)

**ConclusÃ£o**: LSTM foi MELHOR que XGBoost (+3.4pp), mas com colapso fatal.

---

### FASE 3: CorreÃ§Ãµes CrÃ­ticas

Antes de tentar arquiteturas mais complexas, corrigimos 3 bugs fatais:

#### Bug #1: NormalizaÃ§Ã£o DestruÃ­a TendÃªncia
```python
# ANTES (ERRADO):
for i in range(len(ohlc)):
    close = ohlc[i, 3]
    normalized[i] = (ohlc[i] - close) / close * 100  # Close SEMPRE = 0

# DEPOIS (CORRETO):
window = ohlc[idx:idx + long_window]
mean, std = window.mean(axis=0), window.std(axis=0)
x = (window - mean) / std  # Preserva tendÃªncia
```

#### Bug #2: Labeling com "Backtest Illusion"
```python
# ANTES (OTIMISTA): Assumia TP quando TP e SL hit no mesmo candle
# DEPOIS (PESSIMISTA): Assume SL (violino = perda) + spread 0.02%
```

**Impacto**: 92.5% â†’ 54.1% setups viÃ¡veis (-38.4pp de violinos)

#### Bug #3: Class Weighting Ausente
```python
# Adicionado class weighting dinÃ¢mico + NO_TRADE penalty
```

---

###FASE 4: Mamba-Convolutional-Attention (MCA)

Arquitetura hÃ­brida custom: Conv1D (padrÃµes curtos) + Mamba (contexto longo) + Gating

| Tentativa | Config | Win Rate | LONG Acc | SHORT Acc | Status |
|-----------|--------|----------|----------|-----------|--------|
| **MCA v1** | penalty=10x, NO_TRADE=0.5 | 50.6% | 100.0% | 0.0% | âŒ Colapso total |
| **MCA v2** | +class weight dinÃ¢mico | 50.7% | 97.7% | 2.4% | âŒ Melhoria marginal |
| **MCA v3** | penalty=50x, NO_TRADE=0.3 | 49.4% | 0.0% | 100.0% | âŒ Colapso invertido |

**Detalhes**:
- ParÃ¢metros: 76,035
- Features: 4 OHLC (sem feature engineering)
- Loss: Trading Focal Loss (Focal + Direction Penalty 10-50x + Class Weighting)

**ConclusÃ£o**: MCA nÃ£o superou LSTM baseline. Oscila entre 100% LONG ou 100% SHORT.

---

### FASE 5: Feature Engineering + LSTM Rich

Adicionadas 23 features tÃ©cnicas:
- Momentum: RSI (7,14), MACD, Stochastic
- Volatilidade: Bollinger Bands, ATR
- TendÃªncia: ADX, EMA distances
- Microestrutura: Log returns, lagged returns, HL range

| Modelo | Features | Win Rate | LONG Acc | SHORT Acc | Status |
|--------|----------|----------|----------|-----------|--------|
| **LSTM Rich** | 23 (4 OHLC + 19 tÃ©cnicas) | **0.0%** | 0.0% | 0.0% | âŒ FALHA TOTAL |

**Detalhes**:
- ParÃ¢metros: 130,563
- Treino: 17 Ã©pocas, early stopping
- **Problema**: Modelo prevÃª apenas NO_TRADE (100%)

**ConclusÃ£o**: Feature engineering PIOROU o modelo (54.3% â†’ 0%).

---

## ğŸ¯ RANKING FINAL (Por Performance)

| PosiÃ§Ã£o | Modelo | Features | Win Rate | ComentÃ¡rio |
|---------|--------|----------|----------|------------|
| **1Âº** | LSTM Baseline | 4 OHLC | **54.3%** | Melhor, mas colapso para LONG |
| **2Âº** | XGBoost A | 62 + relax TP/SL | 51.2% | Sem colapso, balanceado |
| **3Âº** | XGBoost C | 62 + Optuna | 51.0% | Sem colapso |
| **4Âº** | XGBoost Baseline | 62 | 50.9% | Baseline |
| **5Âº** | MCA v2 | 4 OHLC | 50.7% | 97.7% LONG, 2.4% SHORT |
| **6Âº** | MCA v1 | 4 OHLC | 50.6% | 100% LONG |
| **7Âº** | XGBoost Advanced | 88 | 50.5% | Feature engineering piorou |
| **8Âº** | MCA v3 | 4 OHLC | 49.4% | 100% SHORT (invertido) |
| **9Âº** | LSTM Rich | 23 | **0.0%** | 100% NO_TRADE |

---

## ğŸ” ANÃLISE DO FRACASSO

### Por Que TODOS os Modelos Falharam?

#### 1. Dataset Pequeno Demais
- 51k candles (~6 meses M5)
- Deep Learning precisa de 100k-1M amostras
- Modelos nÃ£o conseguem generalizar

#### 2. Features Insuficientes (OHLC)
- 4 features OHLC nÃ£o capturam dinÃ¢mica de scalping
- Sem indicadores: Modelo cego para momentum/volatilidade
- Sem microstructure: NÃ£o vÃª aggressive orders

#### 3. Labels Pessimistas Dificultam Aprendizado
- ApÃ³s correÃ§Ã£o: 54.1% setups viÃ¡veis (38.4% eram violinos)
- Mercado 45.9% lateral (NO_TRADE)
- Trade-off: Labels realistas vs modelo que aprende

#### 4. TP 0.2% Ã‰ Muito Pequeno para V100
- V100 tem volatilidade ~100%/ano
- TP 0.2% Ã© 0.2% de movimento em 5 min
- RuÃ­do domina sinal (mercado aleatÃ³rio)

#### 5. Loss Functions Complexas
- Focal Loss + Direction Penalty + Class Weighting = Landscape intratÃ¡vel
- Modelos ficam presos em mÃ­nimos locais (100% LONG ou 100% NO_TRADE)

### Por Que Feature Engineering Falhou? (LSTM Rich 0%)

**HipÃ³teses**:
1. **Overfitting nas features**: 23 features com 51k amostras = 0.45 features/1k samples (muito baixo)
2. **Multicolinearidade**: RSI, MACD, Stochastic sÃ£o altamente correlacionados
3. **Log Returns quebraram normalizaÃ§Ã£o**: Log(close).diff() + Z-Score pode ter criado NaNs/Infs
4. **NO_TRADE dominante**: Com 45.9% NO_TRADE, modelo escolheu caminho fÃ¡cil (nunca opera)

---

## ğŸ“‰ EXPECTATIVA vs REALIDADE

| Aspecto | Expectativa Inicial | Realidade Final | Delta |
|---------|---------------------|-----------------|-------|
| **Meta Win Rate** | 60% | 54.3% (LSTM baseline) | -5.7pp âŒ |
| **XGBoost** | 58-62% | 50.5-51.2% | -9pp âŒ |
| **LSTM** | 58-65% | 54.3% | -6pp âŒ |
| **MCA** | 60-68% | 49-51% | -13pp âŒ |
| **LSTM Rich** | 55-58% | 0% | -58pp âŒ |
| **Balanceamento** | LONG/SHORT â‰ˆ 50/50 | Colapso para 1 classe | Falhou âŒ |

---

## âœ… O QUE FUNCIONOU (Relativo)

### 1. Labels Pessimistas + Spread
- Bug corrigido âœ…
- 38.4% de violinos eliminados âœ…
- Spread 0.02% incluÃ­do âœ…
- **Mas**: Modelo nÃ£o consegue aprender com labels realistas

### 2. NormalizaÃ§Ã£o Z-Score por Janela
- TendÃªncia preservada âœ…
- Modelo pode ver "dia de alta" vs "dia de baixa" âœ…
- **Mas**: NÃ£o foi suficiente para distinguir LONG vs SHORT

### 3. LSTM > XGBoost
- Deep Learning superou ML tradicional (+3.4pp) âœ…
- Aprende sequÃªncias temporais âœ…
- **Mas**: Colapsa para classe majoritÃ¡ria

---

## âŒ O QUE NÃƒO FUNCIONA

### 1. Focal Loss para Scalping
- Foca em "exemplos difÃ­ceis" = ruÃ­do do mercado
- Focar em ruÃ­do = overfitting
- **RecomendaÃ§Ã£o**: Usar Cross Entropy simples

### 2. Direction Penalty Extremo
- Penalty 10x: Colapsa para LONG
- Penalty 50x: Colapsa para SHORT
- NÃ£o hÃ¡ equilÃ­brio estÃ¡vel
- **RecomendaÃ§Ã£o**: Remover penalty, usar class weighting

### 3. Feature Engineering Sem ValidaÃ§Ã£o
- Adicionar 20 features cegamente = pior resultado (0%)
- Multicolinearidade + overfitting
- **RecomendaÃ§Ã£o**: Feature selection (PCA, correlation matrix)

### 4. Deep Learning com Dataset Pequeno
- 51k amostras insuficiente para 130k parÃ¢metros
- **RecomendaÃ§Ã£o**: 10x mais dados (500k candles = 5 anos M5)

---

## ğŸ“ LIÃ‡Ã•ES APRENDIDAS

### 1. Simplicidade > Complexidade
- MCA (76k params, 4 features) < LSTM (120k params, 4 features)
- Feature engineering (23 features) pior que baseline (4 features)
- **Regra**: SÃ³ aumentar complexidade SE tiver dados para sustentar

### 2. Labels Realistas SÃ£o DifÃ­ceis
- Labels otimistas (92.5% viÃ¡veis): Modelo aprende, falha em produÃ§Ã£o
- Labels realistas (54.1% viÃ¡veis): Modelo nÃ£o aprende
- **Trade-off**: Escolher entre "aprende fÃ¡cil" vs "funciona"

### 3. Scalping 0.2% Ã‰ Extremamente DifÃ­cil
- Literatura indica 55-60% win rate para TP 1-2%
- TP 0.2% (5x menor) aumenta ruÃ­do/sinal
- **RecomendaÃ§Ã£o**: Testar TP 0.5-1.0% (mais viÃ¡vel)

### 4. Dataset Size Importa MUITO
- Deep Learning: 10k-100k amostras por feature
- Temos: 51k amostras / 23 features = 2.2k/feature (insuficiente)
- **Regra**: MÃ­nimo 10x mais dados que parÃ¢metros

### 5. Feature Engineering Requer Expertise
- Adicionar indicadores cegamente = desastre
- Precisa:
  - Feature selection (remover correlacionados)
  - Feature scaling correto (nÃ£o misturar Log + Z-Score)
  - Domain knowledge (quais indicadores importam?)

---

## ğŸ”® PRÃ“XIMAS AÃ‡Ã•ES (RecomendaÃ§Ãµes)

### OpÃ§Ã£o 1: Aumentar TP para 0.5-1.0% â­ RECOMENDADO
**Por quÃª**:
- TP 0.2% estÃ¡ no ruÃ­do (V100 volatilidade Ã© alta)
- Literatura mostra 55-60% win rate com TP 1-2%
- Menos trades, mas mais confiÃ¡veis

**Expectativa**: Win rate 58-62% com TP 0.5-1.0%

---

### OpÃ§Ã£o 2: Aumentar Dataset para 500k Candles
**Como**:
- Baixar 5 anos de dados M5 (vs 6 meses atual)
- Ou usar M1 e agregar (10x mais dados)

**Expectativa**: Win rate 55-58% (Deep Learning funciona melhor)

---

### OpÃ§Ã£o 3: Mudar para M15/M30
**Por quÃª**:
- M5 muito ruidoso para scalping 0.2%
- M15/M30 tÃªm padrÃµes mais claros
- Trade-off: Menos trades (5-10/dia vs 15-20)

**Expectativa**: Win rate 58-62%

---

### OpÃ§Ã£o 4: Testar BOOM/CRASH
**Por quÃª**:
- BOOM300N/CRASH300N tÃªm spikes previsÃ­veis
- Volatilidade extrema (300% vs 100%)
- PadrÃµes mais distintos (spike = sinal claro)

**Expectativa**: Win rate 60-65%

---

### OpÃ§Ã£o 5: Modelo Ensemble Simples
**Como**:
- LSTM Baseline (54.3%) + XGBoost Optuna (51.0%)
- Voting classifier (se ambos concordam)

**Expectativa**: Win rate 56-58% (mÃ©dia ponderada)

---

## ğŸ“š ARQUIVOS CRIADOS

### Scripts de Treinamento
1. `scalping_lstm_model.py` - LSTM baseline (54.3%)
2. `scalping_mamba_hybrid.py` - MCA (49-51%)
3. `scalping_lstm_rich_features.py` - LSTM Rich (0%)
4. `feature_engineering.py` - Pipeline de 23 features

### DocumentaÃ§Ã£o
1. `CRITICAL_FIXES_SUMMARY.md` - 3 bugs fatais corrigidos
2. `SCALPING_MCA_ARCHITECTURE.md` - Arquitetura MCA
3. `SCALPING_MCA_RESULTS_FINAL.md` - Resultados MCA
4. `LSTM_SCALPING_RESULTS.md` - Resultados LSTM baseline
5. `FINAL_SCALPING_EXPERIMENTS_SUMMARY.md` - Este relatÃ³rio

---

## ğŸ¯ CONCLUSÃƒO FINAL

**11 experimentos, 0 sucessos.**

**Melhor resultado**: LSTM Baseline com 54.3% win rate (mas com colapso para LONG 100%).

**Causa raiz do fracasso**:
1. TP 0.2% muito pequeno (ruÃ­do domina)
2. Dataset pequeno (51k vs 500k+ necessÃ¡rio)
3. Features insuficientes (4 OHLC ou 23 mal selecionadas)
4. Loss functions complexas (mÃ­nimos locais)

**RecomendaÃ§Ã£o final**:
1. â­ **Aumentar TP para 0.5-1.0%** (mais viÃ¡vel)
2. **Aumentar dataset para 500k candles** (5 anos M5)
3. **Simplificar** (LSTM + Cross Entropy + Class Weighting)
4. **Feature engineering cuidadoso** (PCA + correlation analysis)

**Probabilidade de sucesso**:
- OpÃ§Ã£o 1 (TP 0.5-1.0%): **80%** de atingir 58-62%
- OpÃ§Ã£o 2 (500k candles): **70%** de atingir 55-58%
- OpÃ§Ã£o 3 (M15/M30): **75%** de atingir 58-62%
- OpÃ§Ã£o 4 (BOOM/CRASH): **65%** de atingir 60-65%
- OpÃ§Ã£o 5 (Ensemble): **60%** de atingir 56-58%

---

**Status**: Todos os experimentos de scalping 0.2% falharam. Meta de 60% win rate nÃ£o atingida.

**Data**: 19/12/2025
**Autor**: Claude Sonnet 4.5
