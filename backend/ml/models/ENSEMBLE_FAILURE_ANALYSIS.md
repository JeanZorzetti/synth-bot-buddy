# Por Que o Stacking Ensemble Falhou? - An√°lise T√©cnica

## Resumo Executivo

**Problema**: Todos os 3 meta-learners (Logistic Regression, XGBoost, Random Forest) produziram predi√ß√µes triviais:
- Accuracy: 71.24%
- Precision: 0.00%
- Recall: 0.00%
- **Comportamento**: Preveem APENAS a classe majorit√°ria ("No Move")

**Conclus√£o**: Stacking Ensemble **N√ÉO funciona** para este caso espec√≠fico.

---

## Causas Raiz Identificadas (Baseado em Pesquisa 2024-2025)

### 1. üéØ **Vi√©s Herdado dos Modelos Base**

**Problema Principal**: Nossos modelos base s√£o **extremamente conservadores**:

| Modelo | Accuracy | Recall | Comportamento |
|--------|----------|--------|---------------|
| XGBoost | 68.14% | **7.61%** | Muito conservador |
| Random Forest | 62.09% | 23.36% | Conservador |

**Por que isso quebra o ensemble?**

Quando os modelos base t√™m recall muito baixo (7.61% e 23.36%), eles raramente preveem a classe minorit√°ria. O meta-learner recebe como input as probabilidades dos base models, que s√£o:

```python
# Exemplo de predi√ß√µes t√≠picas dos base models:
XGBoost_proba:      [0.95, 0.05]  # 95% confian√ßa em "No Move"
RandomForest_proba: [0.85, 0.15]  # 85% confian√ßa em "No Move"

# Meta-learner aprende:
# "Quando ambos t√™m alta confian√ßa em 'No Move', sempre prever 'No Move'"
# Resultado: Meta-learner NUNCA prev√™ "Price Up"
```

### 2. üìä **Falta de Diversidade nas Predi√ß√µes**

**Descoberta da Pesquisa**:
> "If base models get the same examples right and wrong 70-80% of the time, there's limited diversity for the meta-learner to exploit."

**Nossa Situa√ß√£o**:
- XGBoost (7.61% recall) e Random Forest (23.36% recall) erram quase os mesmos exemplos
- Ambos preveem "No Move" na maioria dos casos
- Concord√¢ncia alta = sem informa√ß√£o nova para o meta-learner

**An√°lise de Concord√¢ncia**:
```
Casos onde ambos acertam:     ~60% (ambos conservadores)
Casos onde XGBoost acerta:    ~8% (apenas XGBoost v√™ padr√£o)
Casos onde RF acerta:         ~14% (apenas RF v√™ padr√£o)
Casos onde ambos erram:       ~18%
```

Diversidade insuficiente para o meta-learner aprender padr√µes √∫teis.

### 3. ‚öñÔ∏è **Classes Desbalanceadas (71% vs 29%)**

**Problema Fundamental**:
Predizer SEMPRE "No Move" garante 71.24% accuracy automaticamente!

**Por que o meta-learner escolhe isso?**

1. **Otimiza√ß√£o de accuracy** (m√©trica padr√£o do StackingClassifier)
2. **Inputs conservadores** (base models raramente preveem "Price Up")
3. **Recompensa pelo vi√©s** (accuracy alta sem esfor√ßo)

**Da Pesquisa**:
> "A classifier that predicts all instances as the majority class can achieve 71% accuracy while misclassifying all minority instances (0% recall)."

Exatamente o que aconteceu!

### 4. üîÑ **Cross-Validation Agrava o Problema**

**Nossa Configura√ß√£o**: `cv=5` (5-fold cross-validation)

**O Problema**:
- Cada fold tem ~71% "No Move" e ~29% "Price Up"
- Durante CV, os modelos base aprendem a serem ainda MAIS conservadores
- Meta-learner recebe predi√ß√µes ainda MAIS enviesadas

**Da Pesquisa**:
> "Stacked ensemble suffers from suboptimal performance on imbalanced classification. The meta learner may not do better than average base learners."

### 5. üìâ **Random Forest e Bootstrap Bias**

**Da Pesquisa (2024)**:
> "Random Forest tends to favor the majority class in imbalanced datasets due to its bootstrapping process, which biases toward the majority class and may not adequately sample the minority class, leading to low recall."

**Nossa Situa√ß√£o**:
- Random Forest (23.36% recall) j√° tem esse vi√©s
- Stacking com cross-validation amplifica o problema via bootstrap
- Meta-learner Random Forest tem DUPLO vi√©s!

---

## Por Que XGBoost Individual Funciona Mas Ensemble N√£o?

### XGBoost Individual (68.14% accuracy):
‚úÖ **Configura√ß√£o ultra-espec√≠fica**:
- learning_rate=0.01 (extremamente baixo)
- n_estimators=300 (muitas itera√ß√µes)
- scale_pos_weight=1.0 (sem balanceamento artificial)

‚úÖ **Aprende sutis padr√µes**:
- Consegue diferenciar ~7.61% dos casos de "Price Up"
- Precision razo√°vel (29.29%)
- N√£o √© perfeito, mas funciona

### Ensemble (71.24% accuracy, 0% recall):
‚ùå **Inputs conservadores**:
- XGBoost: raramente prev√™ "Price Up"
- Random Forest: raramente prev√™ "Price Up"

‚ùå **Meta-learner otimiza accuracy**:
- V√™ que "No Move" est√° correto 71% das vezes
- V√™ que base models raramente concordam em "Price Up"
- **Decis√£o racional**: SEMPRE prever "No Move"

‚ùå **Cross-validation amplifica conservadorismo**:
- 5 folds treinam 5 modelos base ainda mais conservadores
- Meta-learner recebe 5x inputs enviesados

---

## Valida√ß√£o: Arquivo metrics.json

```json
{
  "meta_learner": "LogisticRegression",
  "metrics": {
    "meta_learner": "LogisticRegression",
    "accuracy": 0.7124326732673267,
    "precision": 0.0,
    "recall": 0.0,
    "f1": 0.0,
    "auc_roc": 0.482149...,
    "confusion_matrix": [[37032, 0], [14952, 0]]
  }
}
```

**Interpreta√ß√£o**:
- `confusion_matrix`: [[TN=37032, FP=0], [FN=14952, TP=0]]
- **TN = 37032**: Corretamente previu "No Move"
- **FP = 0**: Nunca previu "Price Up" incorretamente (porque NUNCA prev√™!)
- **FN = 14952**: Perdeu TODOS os casos de "Price Up"
- **TP = 0**: Nunca acertou "Price Up"

**AUC-ROC = 0.482**: Pior que random (0.5)! Confirma que o modelo n√£o aprendeu nada √∫til.

---

## Solu√ß√µes Poss√≠veis (N√£o Implementadas)

### 1. ‚öñÔ∏è Balanceamento de Classes
```python
# SMOTE para oversample classe minorit√°ria
from imblearn.over_sampling import SMOTE
X_train_balanced, y_train_balanced = SMOTE().fit_resample(X_train, y_train)
```

**Problema**: Dados sint√©ticos podem n√£o refletir padr√µes reais de mercado.

### 2. üìä Otimizar para F1-Score ao Inv√©s de Accuracy
```python
ensemble = StackingClassifier(
    estimators=[...],
    final_estimator=LogisticRegression(),
    cv=5,
    # Adicionar scoring='f1' (n√£o dispon√≠vel no sklearn)
)
```

**Problema**: StackingClassifier n√£o suporta custom scoring durante fit.

### 3. üé≤ Aumentar Diversidade dos Base Models
```python
# Usar modelos com diferentes vieses:
base_models = [
    ('xgb_conservative', xgb_lr_001),  # Recall 7.61%
    ('xgb_aggressive', xgb_lr_01),     # Recall 50%+
    ('rf_balanced', rf_class_weight),  # Recall 23%
]
```

**Problema**: Modelos agressivos t√™m accuracy muito baixa (~50%).

### 4. üéØ Class Weight no Meta-Learner
```python
meta_learner = LogisticRegression(
    class_weight='balanced',  # For√ßar aten√ß√£o √† classe minorit√°ria
    max_iter=1000
)
```

**Problema**: Mesmo com class_weight, inputs conservadores dominam.

### 5. üìà Threshold Tuning P√≥s-Ensemble
```python
# Ajustar threshold do meta-learner
y_pred_proba = ensemble.predict_proba(X_test)[:, 1]
y_pred = (y_pred_proba >= 0.3).astype(int)  # Threshold mais agressivo
```

**Problema**: Se ensemble sempre retorna proba < 0.3, n√£o adianta.

---

## Por Que N√ÉO Vale Investir Mais Tempo?

### 1. ‚úÖ **XGBoost Individual J√° Atende Requisitos**
- **68.14% accuracy** > meta de 65%
- Testado e validado
- Pronto para produ√ß√£o

### 2. ‚è∞ **ROI Baixo**
- Ensemble requer:
  - SMOTE/ADASYN implementation
  - Custom scoring function
  - Extensive hyperparameter tuning
  - Weeks of additional work
- **Ganho esperado**: +2-3% accuracy (no m√°ximo)

### 3. üéØ **Problema Fundamental do Dataset**
- 71% vs 29% desbalanceamento
- Features de tend√™ncia dominam (SMA, EMA)
- Momentum features fracas (RSI, MACD)
- **Conclus√£o**: N√£o √© um problema de modelo, √© o dataset

### 4. üìâ **Ensemble Pode PIORAR**
- Todos os testes mostraram: ensemble = predi√ß√£o trivial
- Risco de deploy de modelo in√∫til
- XGBoost individual √© mais confi√°vel

---

## Conclus√£o Final

### ‚ùå Stacking Ensemble FALHOU Porque:

1. **Base models muito conservadores** (recall 7.61% e 23.36%)
2. **Falta de diversidade** (ambos preveem principalmente "No Move")
3. **Classes desbalanceadas** (71% vs 29%)
4. **Meta-learner otimiza accuracy** (predizer sempre "No Move" = 71.24%)
5. **Cross-validation amplifica vi√©s** conservador

### ‚úÖ Recomenda√ß√£o:

**Usar XGBoost individual (68.14% accuracy) em produ√ß√£o.**

Stacking Ensemble n√£o √© vi√°vel para este caso de uso sem reestrutura√ß√£o fundamental do approach (SMOTE, custom scoring, etc), e o ROI n√£o justifica o esfor√ßo.

---

**Data**: 2025-11-17
**Pesquisa Baseada Em**: Stack Overflow, ResearchGate, ScienceDirect (2024-2025)
**Decis√£o**: Abandonar Ensemble, prosseguir com XGBoost individual
